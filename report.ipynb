{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac65f30-3c41-4079-8db5-430ac346ce7d",
   "metadata": {},
   "source": [
    "# <b> CSCI 580 Artifical Intelligence: Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551017d2-f52b-45b9-9a68-c861e0b1bb9b",
   "metadata": {},
   "source": [
    "This report documents our model for handwritten digit recognition. Specifically, it will cover various attributes of our model and its overall performance. The people in our team who worked on the project are <b> Harsh Sharma, Marco U Calderon, Luis Manuel Melgoza, and Kamaldeep Singh <b>\n",
    "\n",
    "Here is a link to a GitHub repository including all relevant materials:  (https://github.com/HarshTheSharma/Final580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dd44c2-f728-42c5-a2a0-8b5636dd42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13b2b3-3693-444b-a532-7991baa46d98",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701031b-baa8-46ab-afbd-0c2b66a0e7f5",
   "metadata": {},
   "source": [
    "## <b> Our Model's Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7fe76-0608-4d87-b0af-9da0b3e323c8",
   "metadata": {},
   "source": [
    "<p> A high-level framework for our solution involves using a Multilayer Perceptron (MLP), which is a fully connected feedforward neural network. This framework is implemented using PyTorch and is designed to classify 28 x 28 grayscale handwritten digit images from the MNIST and team-collected datasets.\n",
    "\n",
    "Regarding details about our Neural Net architecture, we have exactly four linear layers: three hidden layers and one output layer. Our model starts with hundreds of neurons that gradually decrease in number as we progress through each layer. We end up with ten neurons in our output layer, corresponding to the 10 digit classes. The total number of weights excluding Batch Norm parameters is around 566,528. Furthermore, our model also uses the Rectified Linear Unit (ReLU) activation function after each hidden layerâ€™s batch normalization, which stabilizes training alongside dropout in the first two hidden layers to avoid overfitting.\n",
    "\n",
    "In addition to our Neural Net architecture, our model is driven by carefully tuned hyperparameters. The model uses the Adam optimizer to update weights with the standard cross-entropy loss function for multi-class classification. Its initial learning rate is set to 0.0005, with L2 regularization (weight decay) of 0.0001 to reduce overfitting. Additionally, a Reduce Learning Rate on Plateau is included, which halves the learning rate if the validation loss plateaus for consecutive epochs. Speaking of epochs, we are doing 100 epochs on the MNIST dataset, and handwritten digits made by 10 groups with 4 members each.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2434f-7352-43cd-b24e-dc1306b4f3e5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b8240-1ff9-4918-9838-c2b7df230421",
   "metadata": {},
   "source": [
    "## <b> Detailed Aspects of Our Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f2c43-afa9-47c5-8d7d-b6a016b68192",
   "metadata": {},
   "source": [
    "## Part 1: Data & Augmentation Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6bd28-e9b1-4b3f-b7d7-6d8b81e33cf4",
   "metadata": {},
   "source": [
    "<p>The first major part of our implementation concerns data and augmentation setup. To maximize our model's performance, we apply various transformations to the images, so our model can pick up on varying image types. Here is all of our transformations: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b6c5bf-2f4d-46e3-9402-a8da1628f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaiseDarkPoint(object):\n",
    "    def __init__(self, grayRange=(10, 60)):\n",
    "        self.grayRange = grayRange\n",
    "\n",
    "    def __call__(self, img):\n",
    "        arr = np.array(img).astype(np.float32)\n",
    "        grayVal = np.random.uniform(*self.grayRange)\n",
    "        mask = arr < 30\n",
    "        arr[mask] = arr[mask] + grayVal\n",
    "        arr = np.clip(arr, 0, 255)\n",
    "        return Image.fromarray(arr.astype(np.uint8), mode=\"L\")\n",
    "\n",
    "\n",
    "class LowerWhitePoint(object):\n",
    "    def __init__(self, factorRange=(0.7, 0.95)):\n",
    "        self.factorRange = factorRange\n",
    "\n",
    "    def __call__(self, img):\n",
    "        arr = np.array(img, dtype=np.float32)\n",
    "        factor = float(np.random.uniform(self.factorRange[0], self.factorRange[1]))\n",
    "        arr = arr * factor\n",
    "        arr = np.clip(arr, 0, 255)\n",
    "        return Image.fromarray(arr.astype(np.uint8), mode=\"L\")\n",
    "\n",
    "\n",
    "class AddNoise(object):\n",
    "    def __init__(self, noiseStd=0.05):\n",
    "        self.noiseStd = noiseStd\n",
    "\n",
    "    def __call__(self, img):\n",
    "        arr = np.array(img).astype(np.float32)\n",
    "        noise = np.random.normal(0, self.noiseStd * 255, arr.shape)\n",
    "        arr = arr + noise\n",
    "        arr = np.clip(arr, 0, 255)\n",
    "        return Image.fromarray(arr.astype(np.uint8), mode=\"L\")\n",
    "\n",
    "\n",
    "class BubblyDigits(object):\n",
    "    def __init__(self, blurRange=(0.4, 1.0), contrastRange=(1.1, 1.6)):\n",
    "        self.blurRange = blurRange\n",
    "        self.contrastRange = contrastRange\n",
    "\n",
    "    def __call__(self, img):\n",
    "        sigma = float(np.random.uniform(self.blurRange[0], self.blurRange[1]))\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        c = float(np.random.uniform(self.contrastRange[0], self.contrastRange[1]))\n",
    "        img = ImageEnhance.Contrast(img).enhance(c)\n",
    "        return img\n",
    "\n",
    "\n",
    "class JPEGCompression(object):\n",
    "    def __init__(self, qualityRange=(40, 80)):\n",
    "        self.qualityRange = qualityRange\n",
    "\n",
    "    def __call__(self, img):\n",
    "        q = int(np.random.randint(self.qualityRange[0], self.qualityRange[1]))\n",
    "        buf = BytesIO()\n",
    "        img.save(buf, format=\"JPEG\", quality=q)\n",
    "        buf.seek(0)\n",
    "        return Image.open(buf).convert(\"L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31b4e1-c6fe-4bfd-9fe8-b8a0f87605b9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> And here is how we are applying the transformations to our images: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f56359-325e-49d4-9295-2ffef2aa910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTransform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomApply(\n",
    "            [\n",
    "                transforms.Pad(4, fill=0),\n",
    "                transforms.RandomCrop(28),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        transforms.RandomApply(\n",
    "            [\n",
    "                transforms.RandomAffine(\n",
    "                    degrees=(-5, 20),\n",
    "                    translate=(0.25, 0.25),\n",
    "                    scale=(0.6, 1.1),\n",
    "                    fill=0,\n",
    "                )\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        transforms.RandomApply([AddNoise()], p=0.1),\n",
    "        transforms.RandomApply([BubblyDigits()], p=0.5),\n",
    "        transforms.RandomApply([LowerWhitePoint()], p=0.4),\n",
    "        transforms.RandomApply([RaiseDarkPoint()], p=0.4),\n",
    "        transforms.RandomApply(\n",
    "            [transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.5))], p=1\n",
    "        ),\n",
    "        transforms.RandomApply([JPEGCompression()], p=0.25),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266c9c2-e2ec-44e3-b19e-fd6ca114614c",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "<p> Following the image transformations, we define our training and test datasets, which will be incredibly useful to train and evaluate our model: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82cfb50b-6f56-4d97-b853-2145e12a2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = datasets.MNIST(\n",
    "    \"~/.pytorch/MNIST_data/\", download=True, train=True, transform=trainTransform\n",
    ")\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=64, shuffle=True)\n",
    "\n",
    "testSet = datasets.MNIST(\n",
    "    \"~/.pytorch/MNIST_data/\", download=True, train=False, transform=transform\n",
    ")\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ec0cf-b993-41b4-b7b7-95eccd3f269e",
   "metadata": {},
   "source": [
    "<b>\n",
    "    \n",
    "## Part 2: Training Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c129c288-97d4-49d3-bfd6-ec424a6d92ec",
   "metadata": {},
   "source": [
    "<p> The next major part of our implementation concerns the main loop for training our model. We go through each image and its label, provide the data to our model, and then record the results. First, we have to define our model: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b1455b-5871-47f9-9ab3-57e5d7be48eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "MNISTMLP(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Device\n",
    "# ------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class MNISTMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MNISTMLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67be6d0-4695-49a1-a743-44dac4640693",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p>And now we can run it and record the results: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a38b02-5152-4414-bdbe-0851476604cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 100\n",
    "allLosses = []\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    batchLosses = []\n",
    "\n",
    "    for images, labels in trainLoader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val = loss.item()\n",
    "        runningLoss += val\n",
    "        batchLosses.append(val)\n",
    "\n",
    "    epochLoss = runningLoss / len(trainLoader)\n",
    "    allLosses.append(batchLosses)\n",
    "    scheduler.step(epochLoss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{numEpochs}, Loss: {epochLoss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(allLosses[0], label=\"Epoch 1\")\n",
    "plt.xlabel(\"Batch index\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss per Batch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419de09-bbc2-44ff-b6ee-cc8cc2ec001e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
